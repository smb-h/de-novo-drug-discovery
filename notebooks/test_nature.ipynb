{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 12:05:00.528373: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-15 12:05:00.622233: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from copy import copy\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow import keras\n",
    "\n",
    "from rdkit.Chem import MolStandardize, MolFromSmiles, MolToSmiles\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c1ccc(cc1)[N-]S(=O)(=O)CCCCCCC(=O)NO',\n",
       " 'c1cc(ccc1[N+](=O)[O-])OC[C@H]2CO2',\n",
       " 'c1cc(ccc1[N+](=O)[O-])OC[C@@H]2CO2',\n",
       " 'c1cc(c(cc1[N+](=O)[O-])[N+](=O)[O-])Cl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/raw/ZINC_results.smi\") as f:\n",
    "    smiles = [s.split(\"\\t\")[0].rstrip() for s in f]\n",
    "smiles[:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nature Token size:  35\n",
      "Molecular Informatics Token size:  44\n"
     ]
    }
   ],
   "source": [
    "one_hot_nature = ['C', 'N', 'O', 'H', 'F', 'Cl', 'P', 'B', 'Br', 'S', 'I', 'Si', '#', '(', ')', '+', '-', '1', '2', '3',\n",
    "               '4', '5', '6', '7', '8', '=', '[', ']', '@', 'c', 'n', 'o', 's', 'X', '.']\n",
    "print(\"Nature Token size: \", len(one_hot_nature))\n",
    "atoms = [\"Al\", \"As\", \"B\", \"Br\", \"C\", \"Cl\", \"F\", \"H\", \"I\", \"K\", \"Li\", \"N\", \"Na\", \"O\", \"P\", \"S\", \"Se\", \"Si\", \"Te\"]\n",
    "special = [\"(\", \")\", \"[\", \"]\", \"=\", \"#\", \"%\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"+\", \"-\", \"se\", \"te\", \"c\", \"n\", \"o\", \"s\"]\n",
    "print(\"Molecular Informatics Token size: \", len(atoms) + len(special))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmilesTokenizer(object):\n",
    "    def __init__(self):\n",
    "        atoms = ['C', 'N', 'O', 'H', 'F', 'Cl', 'P', 'B', 'Br', 'S', 'I', 'Si']\n",
    "        special = ['#', '(', ')', '+', '-', '1', '2', '3', '4', '5', '6', '7', '8', '=', '[', ']', '@', 'c', 'n', 'o', 's', 'X', '.']\n",
    "        padding = [\"G\", \"E\"]\n",
    "\n",
    "        self.table = sorted(atoms, key=len, reverse=True) + special + padding\n",
    "        table_len = len(self.table)\n",
    "\n",
    "        self.table_2_chars = list(filter(lambda x: len(x) == 2, self.table))\n",
    "        self.table_1_chars = list(filter(lambda x: len(x) == 1, self.table))\n",
    "\n",
    "        self.one_hot_dict = {}\n",
    "        for i, symbol in enumerate(self.table):\n",
    "            vec = np.zeros(table_len, dtype=np.float32)\n",
    "            vec[i] = 1\n",
    "            self.one_hot_dict[symbol] = vec\n",
    "\n",
    "    def tokenize(self, smiles):\n",
    "        smiles = smiles + \" \"\n",
    "        N = len(smiles)\n",
    "        token = []\n",
    "        i = 0\n",
    "        while i < N:\n",
    "            c1 = smiles[i]\n",
    "            c2 = smiles[i : i + 2]\n",
    "\n",
    "            if c2 in self.table_2_chars:\n",
    "                token.append(c2)\n",
    "                i += 2\n",
    "                continue\n",
    "\n",
    "            if c1 in self.table_1_chars:\n",
    "                token.append(c1)\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        return token\n",
    "\n",
    "    def one_hot_encode(self, smiles, pad_len=-1):\n",
    "        one_hot = ['C', 'N', 'O', 'H', 'F', 'Cl', 'P', 'B', 'Br', 'S', 'I', 'Si', '#', '(', ')', '+', '-', '1', '2', '3',\n",
    "                '4', '5', '6', '7', '8', '=', '[', ']', '@', 'c', 'n', 'o', 's', 'X', '.']\n",
    "        \n",
    "        smiles = smiles + '.'\n",
    "        if pad_len < 0:\n",
    "            vec = np.zeros((len(smiles), len(one_hot)))\n",
    "        else:\n",
    "            vec = np.zeros((pad_len, len(one_hot)))\n",
    "        cont = True\n",
    "        j = 0\n",
    "        i = 0\n",
    "        while cont:\n",
    "            \n",
    "            try:\n",
    "                if smiles[i + 1] in ['r', 'i', 'l']:\n",
    "                    sym = smiles[i:i + 2]\n",
    "                    i += 2\n",
    "                else:\n",
    "                    sym = smiles[i]\n",
    "                    i += 1\n",
    "            except:\n",
    "                print(f'smiles[i + 1] not working, value smiles {smiles}')\n",
    "            if sym in one_hot:\n",
    "                vec[j, one_hot.index(sym)] = 1\n",
    "            else:\n",
    "                vec[j, one_hot.index('X')] = 1\n",
    "            j += 1\n",
    "            if smiles[i] == '.' or j >= (pad_len - 1) and pad_len > 0:\n",
    "                vec[j, one_hot.index('.')] = 1\n",
    "                cont = False\n",
    "        return vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor(object):\n",
    "    def __init__(self):\n",
    "        self.normarizer = MolStandardize.normalize.Normalizer()\n",
    "        self.lfc = MolStandardize.fragment.LargestFragmentChooser()\n",
    "\n",
    "    def process(self, smi):\n",
    "        mol = MolFromSmiles(smi)\n",
    "        if mol:\n",
    "            mol = self.normarizer.normalize(mol)\n",
    "            mol = self.lfc.choose(mol)\n",
    "            smi = MolToSmiles(mol, isomericSmiles=False, canonical=True)\n",
    "            return smi\n",
    "        else:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input SMILES num: 5000\n",
      "start preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:03<00:00, 1263.42it/s]\n",
      "100%|██████████| 4999/4999 [00:00<00:00, 62850.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output SMILES num: 4999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pp = Preprocessor()\n",
    "\n",
    "print(f\"input SMILES num: {len(smiles)}\")\n",
    "print(\"start preprocessing...\")\n",
    "\n",
    "smiles = [pp.process(smi) for smi in tqdm(smiles)]\n",
    "# drop duplicates\n",
    "smiles = list(set([s for s in smiles if s]))\n",
    "\n",
    "# token limits (1 to 140)\n",
    "st = SmilesTokenizer()\n",
    "smiles_tokenized = [st.tokenize(smi) for smi in tqdm(smiles)]\n",
    "smiles_processed = []\n",
    "\n",
    "# err = 0\n",
    "# err_tokens = []\n",
    "# for i in range(len(smiles)):\n",
    "#     if smiles[i] != \"\".join(smiles_tokenized[i]):\n",
    "#         print(\"=====================================\")\n",
    "#         print(len(smiles[i]), \" :\", smiles[i])\n",
    "#         print(len(smiles_tokenized[i]), \" :\" ,smiles_tokenized[i])\n",
    "#         for char in smiles[i]:\n",
    "#             if char not in smiles_tokenized[i]:\n",
    "#                 err_tokens.append(char)\n",
    "#         err += 1\n",
    "# print(\"Error: \", err)\n",
    "# print(\"Error Tokens: \", err_tokens)\n",
    "\n",
    "for tokenized in smiles_tokenized:\n",
    "    if 1 <= len(tokenized) <= 140:\n",
    "        smiles_processed.append(tokenized)\n",
    "\n",
    "print(f\"output SMILES num: {len(smiles_processed)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad(tokenized_smi):\n",
    "    return (\n",
    "        [\"G\"] + tokenized_smi + [\"E\"]\n",
    "    )\n",
    "\n",
    "def _padding(data):\n",
    "    padded_smiles = [_pad(t_smi) for t_smi in data]\n",
    "    return padded_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cc1cc(C[NH+](C)Cc2ccc(F)cc2Cl)n[nH]1\n",
      "GCc1cc(C[NH+](C)Cc2ccc(F)cc2Cl)n[nH]1E\n"
     ]
    }
   ],
   "source": [
    "# add paddings\n",
    "print(\"\".join(smiles_processed[0]))\n",
    "smiles_processed = _padding(smiles_processed)\n",
    "print(\"\".join(smiles_processed[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n",
      "===========================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (50,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     _y \u001b[39m=\u001b[39m st\u001b[39m.\u001b[39mone_hot_encode(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(tp_smi[\u001b[39m1\u001b[39m:]))\n\u001b[1;32m     16\u001b[0m     y\u001b[39m.\u001b[39mappend(_y)\n\u001b[0;32m---> 18\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(x, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat32)\n\u001b[1;32m     19\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(y, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     20\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (50,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# one hot encode\n",
    "x, y = [], []\n",
    "\n",
    "# for tp_smi in smiles_processed[:5]:\n",
    "#     print(\"-----------------------------------\")\n",
    "#     print(\"\".join(tp_smi[:-1]))\n",
    "#     print(\"\".join(tp_smi[1:]))\n",
    "\n",
    "smiles_processed = smiles_processed[:50]\n",
    "\n",
    "for tp_smi in smiles_processed:\n",
    "    print(\"===========================\")\n",
    "    _x = st.one_hot_encode(\"\".join(tp_smi[:-1]))\n",
    "    x.append(_x)\n",
    "    _y = st.one_hot_encode(\"\".join(tp_smi[1:]))\n",
    "    y.append(_y)\n",
    "\n",
    "# Problem with different shapes\n",
    "\n",
    "# x = np.array(x, dtype=np.float32)\n",
    "# y = np.array(y, dtype=np.float32)\n",
    "# print(x.shape)\n",
    "# x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('drug_design')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df575d9b3e9895d2442e3df5b270c02c77977dbbc9d135026610c4079aa2b2a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
